{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c7801e-ce68-4f4d-9cfe-96c8f6ce205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "DF_MAIN = 'data/df_main_mod_noretires.csv'\n",
    "\n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.max_rows', 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc9687-0fe0-4c10-885d-98e5f99f6036",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "The model used is RandomForestRegressor form sklearn package. Training is being done with 5-folded cross-validation. (which is a default number of folds if cv is applied).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954184d-a248-42f6-93ba-ed33819db75a",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We get rid of indexes and separate the target from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f76d8d0-1c4b-49e3-9a7c-d17715e0246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DF_MAIN)\n",
    "df = df.drop(['ID_region', 'ID_subregion', 'ID_powiatu', 'year'], axis=1)\n",
    "y = df['p3350-stopień-wykorzystania-miejsc-noclegowych-w-kolejnym-roku']\n",
    "X = df.drop(['p3350-stopień-wykorzystania-miejsc-noclegowych-w-kolejnym-roku'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4faea9-f928-4bc2-bfdf-f51a3f9212b4",
   "metadata": {},
   "source": [
    "## Mocking run\n",
    "\n",
    "We choose to validate our regression model according to MAE (Mean absolute error) score. We might try to construct a default model to estimate a baseline score for further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2027b20-11dd-4e9a-8feb-d1fe36790c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=0)\n",
    "model_base_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a258d622-f51a-47cc-a2c2-0d604d3f8f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.774514246575343"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853fe4f9-2b50-474e-a4ff-19548f947970",
   "metadata": {},
   "source": [
    "## Feature selection and validation\n",
    "\n",
    "We might want to get rid of highly correlated features for the sake of performance. We'll use principal component analysis decomposition method, which is known to work better when feed with normalised data, which we obtain with help of the StandardScaler object. We introduce a pipeline to make things more convinient and perform a grid search for the optimal amount of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15947ce4-1e51-4166-a4c9-0066c81f38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('normalisation', StandardScaler(with_mean=False)),\n",
    "                 ('pca', PCA()),\n",
    "                 ('rfr', RandomForestRegressor())])\n",
    "grid = {'pca__n_components'      : range(24, 40, 1),\n",
    "        'rfr__n_estimators'      : [150],\n",
    "        'rfr__max_depth'         : range(1,20,1)}\n",
    "best_fit_model = GridSearchCV(pipe, param_grid = grid, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb42737-f9e9-4109-9d64-63e7b4c9ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8cda681-0204-464c-a47e-f595e89099a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 26, 'rfr__max_depth': 3, 'rfr__n_estimators': 150} \n",
      " -7.118056326951219\n"
     ]
    }
   ],
   "source": [
    "print(best_fit_model.best_params_, '\\n', best_fit_model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
